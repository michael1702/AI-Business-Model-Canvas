# Hito 5: Despliegue de la aplicaci贸n en IaaS/PaaS

## 1. Selecci贸n del proveedor PaaS (Platform as a Service)

Para el despliegue productivo de la aplicaci贸n AI Business Model Canvas, se ha seleccionado la plataforma Render.

### Justificaci贸n de la elecci贸n:
* **Infraestructura como C贸digo (IaC):** Render permite la configuraci贸n completa de la infraestructura mediante un archivo YAML (`render.yaml`). Esto cumple con el requisito de reproducibilidad y evita configuraciones manuales en la interfaz web.
* **Localizaci贸n en Europa:** Render dispone de una regi贸n en **Frankfurt (Alemania)**. Esto es fundamental para cumplir con la normativa de protecci贸n de datos (GDPR) exigida en las especificaciones del proyecto.
* **Integraci贸n con GitHub:** El despliegue se realiza de forma autom谩tica ("Zero Downtime Deployment") cada vez que se hace un `push` a la rama principal (`main`), siempre que los tests de CI (`ci.yml`) hayan pasado correctamente.
* **Base de datos gestionada:** Provee una instancia de PostgreSQL gestionada, lo cual es m谩s robusto que el archivo SQLite utilizado en el entorno de desarrollo.

---
## 2. Configuraci贸n de la Infraestructura (IaC)

La infraestructura se ha definido en el archivo `render.yaml` situado en la ra铆z del repositorio, orquestando una arquitectura de **microservicios**.

### Descripci贸n del archivo `render.yaml`
El archivo define la orquestaci贸n de **4 servicios web y una base de datos** que se comunican a trav茅s de la red privada de Render:

1.  **Servicios Web:**
    * **Frontend:** Sirve la interfaz de usuario (Flask + Jinja2) y act煤a como Gateway.
    * **User Service:** Gestiona autenticaci贸n y usuarios.
    * **Group Service:** Gestiona la l贸gica de grupos.
    * **BMC Service:** Gestiona la l贸gica de negocio del canvas e integraci贸n con IA.
    * **Configuraci贸n:** Todos utilizan Docker y se inician mediante Gunicorn (`gunicorn --bind 0.0.0.0:$PORT ...`). 
2.  **Base de Datos (`postgres`):**
    * Motor: PostgreSQL.
    * Persistencia: Almacenamiento persistente en disco para asegurar que los datos de usuarios y BMCs no se pierdan entre reinicios.

**Enlace al c贸digo:** [`render.yaml`](../render.yaml)

---

## 3. Monitorizaci贸n y Observabilidad

Para garantizar la operaci贸n continua y detectar incidencias proactivamente, se han implementado herramientas de observabilidad en dos niveles: interno (aplicaci贸n) y externo (disponibilidad).

### 3.1. Monitorizaci贸n de Errores y Rendimiento (Sentry)
Se ha integrado **Sentry** en la aplicaci贸n Flask (`app.py`) para capturar excepciones y m茅tricas de rendimiento en tiempo real.

* **Validaci贸n de la integraci贸n:** Para verificar el correcto funcionamiento del sistema de alertas, se implement贸 una ruta de prueba temporal (`/testerror`) dise帽ada para provocar un fallo intencionado (una divisi贸n por cero).
* **Resultado:** Como se observa en la captura de pantalla, Sentry detect贸 inmediatamente la excepci贸n `ZeroDivisionError`, proporcionando la traza completa (Stack Trace) y el contexto de la petici贸n, lo que demuestra la capacidad de la aplicaci贸n para reportar incidencias cr铆ticas autom谩ticamente.

<img width="1281" height="901" alt="image" src="https://github.com/user-attachments/assets/792852cd-6706-488f-a898-f28ecbb8eca5" />

Adicionalmente, Sentry monitoriza la latencia de las peticiones HTTP (Performance Monitoring), permitiendo identificar cuellos de botella en los endpoints de la API.

*(Opcional: Insertar aqu铆 una captura del tab "Performance" de Sentry)*
### 3.2. Monitorizaci贸n de Disponibilidad (UptimeRobot)
Se utiliza UptimeRobot como monitor sint茅tico externo.

* **Configuraci贸n:** Realiza una petici贸n HTTP `GET` cada 5 minutos al endpoint principal de la aplicaci贸n.
* **Alerta:** En caso de que la respuesta no sea `200 OK` (por ejemplo, ca铆da del servidor o error 503), se env铆a una notificaci贸n inmediata por correo electr贸nico.

<img width="1872" height="950" alt="image" src="https://github.com/user-attachments/assets/64509e73-7056-490a-9e34-ae1c732bd30e" />

---

## 4. Pruebas de Carga (Stress Testing)

Se han realizado pruebas de estr茅s para verificar la estabilidad del despliegue bajo carga concurrente. Para ello se ha utilizado la herramienta Locust.

### Escenario de prueba (`tests/locustfile.py`)
El script de prueba simula un comportamiento realista de usuario:
1.  **Autenticaci贸n:** El usuario virtual intenta hacer login. Si la cuenta no existe (primera ejecuci贸n), se registra autom谩ticamente y luego inicia sesi贸n.
2.  **Navegaci贸n:** Una vez autenticado, el usuario accede repetidamente a su Dashboard de BMCs y a su perfil de usuario.

### Ejecuci贸n y Resultados
* **Configuraci贸n:** 50 usuarios concurrentes con una tasa de crecimiento (spawn rate) de 5 usuarios/segundo.
* **Resultado:** La aplicaci贸n desplegada **en el entorno local** respondi贸 correctamente a todas las peticiones sin errores de servidor (5xx) y manteniendo tiempos de respuesta estables.

**Nota sobre el entorno de pruebas:** Las pruebas de estr茅s se realizaron contra el despliegue local (Docker Compose) en lugar de la versi贸n en la nube. Esto se debe a que la capa de seguridad de Render (Cloudflare) bloquea autom谩ticamente el tr谩fico automatizado de alta frecuencia (Error 429), interpret谩ndolo como un ataque DDoS.

<img width="916" height="66" alt="image" src="https://github.com/user-attachments/assets/670915f9-f37c-41b6-b781-92d031dc15c6" />
Al probar localmente, podemos medir el rendimiento real de los microservicios sin la limitaci贸n del WAF externo.

<img width="1649" height="557" alt="image" src="https://github.com/user-attachments/assets/cd4a2a98-553f-4d71-ae44-fbb9ff94946d" />

<img width="1514" height="904" alt="image" src="https://github.com/user-attachments/assets/ecb765c7-3614-4ab7-a4dc-8a65c3b50748" />


---

## 5. Despliegue

La aplicaci贸n se encuentra desplegada y accesible p煤blicamente en la siguiente URL:

 **[https://aibmc-frontend.onrender.com](https://aibmc-frontend.onrender.com/)**
